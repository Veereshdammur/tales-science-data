{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "    /* DOWNLOAD COMPUTER MODERN FONT JUST IN CASE */\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "\n",
       "    /* GLOBAL TEXT FONT */\n",
       "    div#notebook,\n",
       "    div.output_area pre,\n",
       "    div.output_wrapper,\n",
       "    div.prompt {\n",
       "      font-family: Times new Roman, monospace !important;\n",
       "    }\n",
       "\n",
       "    /* CENTER FIGURE */\n",
       "    .output_png {\n",
       "        display: table-cell;\n",
       "        text-align: center;\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    /* LINK */\n",
       "    a {\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H1 */\n",
       "    h1 {\n",
       "        font-size: 42px !important;\n",
       "        text-align: center;\n",
       "        color: #FF8000;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h2 {\n",
       "        font-size: 32px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h3 {\n",
       "        font-size: 24px !important;\n",
       "    }\n",
       "\n",
       "    /* H2 */\n",
       "    h4 {\n",
       "        font-size: 20px !important;\n",
       "    }\n",
       "\n",
       "    /* PARAGRAPH */\n",
       "    p {\n",
       "        font-size: 16px !important;\n",
       "        text-align: center;\n",
       "    }\n",
       "\n",
       "    /* LIST ITEM */\n",
       "    li {\n",
       "        font-size: 16px !important;\n",
       "    }\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ../common/import_all.py\n",
    "\n",
    "from common.setup_notebook import set_css_style, setup_matplotlib, config_ipython\n",
    "\n",
    "config_ipython()\n",
    "setup_matplotlib()\n",
    "set_css_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A learning machine\n",
    "\n",
    "Machine Learning is that field at the intersection of statistics and computer science that tries to have machines perform tasks somewhat related to intelligence, making them \"understand\" data patterns, generalise learnings to new data points and extract information in the data which isn't immediately visible to the naked eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paradigms of Machine Learning (main ones)\n",
    "\n",
    "There are several ways to separate tasks and problems in machine learning into categories based on the logical way of proceding and the type of outcome desired. The main, traditional ones are *supervised* and *unsupervised* learning, which are different in the approach and the type of data you feed in, but there are some other paradigms which are getting interest in more recent times (for instance reinforcement learning) and also, the distinctions can be not very draconian sometimes.\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "In supervised learning, you teach the machine to learn from data points that have a target value against them specifying the ground truth. \n",
    "\n",
    "In the case of a *regression* you want to predict the value of the dependent variable given the independent variable(s); in the case of a *classification*, you have data separated into categories, identified by their labels and try to predict the target class of the data point. In both cases the machine is trained to learn from existing matches in order to generalise on new data and spit out the target value for those.\n",
    "\n",
    "In fact, *regression* and *classification* are the main problems you tackle in a supervised learning setting.\n",
    "\n",
    "### Unsupervised learning\n",
    "\n",
    "Learning is unsupervised when there are no labels in the training set that specify the ground truth. This type of Machine Learning deals with extracting patterns from the data, understanding and manipulating its structure in order to separate group of points which are somehow similar. \n",
    "\n",
    "*Clustering* is one instance of unsupervised learning: you try to group data points together into groups for similarity; another task is *anomaly detection*, where the computer flag some data point as weird with respect to the rest. Other techniques which usually get classed in this paradigm deal with the shrinking of data points into smaller sets which contain most of the relevant original information, these usually go under the name of *dimensionality reduction*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "### Binary\n",
    "\n",
    "### Multiclass\n",
    "\n",
    "The methods here exposed are used in multiclass classification when the algorithm does not support it naturally (it is suited to binary classification).\n",
    "\n",
    "#### One-vs.-all\n",
    "\n",
    "Also called *one-vs.-rest*, in this technique a single classifier per class is trained: the samples in the training set which are labelled for that class are considered positive and all the other samples negative. A confidence score is drawn for each of these classifiers classifier.\n",
    "\n",
    "For an unseen data point, each classifier gets applied and the predicted label will be the one for which the corresponding classifier has the highest score. \n",
    "\n",
    "The problem with this approach is that the single classifiers are trained on unbalanced sets.\n",
    "\n",
    "#### One-vs.-one\n",
    "\n",
    "In this technique, $\\frac{k(k-1)}{2}$ classifiers get trained, where $k$ is the number of classes: each classifier receives a pair of classes from the set and learns to distinguish between them. \n",
    "\n",
    "For an unseen data point, a voting scheme is applied where all the classifiers are used on it and then the class with the highest number of positives gets predicted.\n",
    "\n",
    "The problem with this approach is that some regions of the input space may receive the same number of votes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage in, garbage out\n",
    "\n",
    "This phrase is used to mean that if poor data is fed into an algorithm, however sophisticated it may be, poor results are obtained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy and eager learning\n",
    "\n",
    "In a *lazy learning* approach, the algorithm outputs the result on test data only after all training data has been ingested and computation made on it. It uses a predictive function that gets approximates locally and is thereby adaptable to changes. An example is kNN.\n",
    "\n",
    "In an *eager learning* approach instead, the predictive function is built during training so that the algorithm can be run on test data along the way. The function is then built globally, making computation less space-consuming. Examples are Naive Bayes and neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble methods\n",
    "\n",
    "Ensemble methods combine predictions from several estimators to improve the ability to generalise to new data. There are two main classes.\n",
    "\n",
    "### Averaging methods\n",
    "\n",
    "The estimators used are independent and their predictions get averaged, to reduce the variance. The main way to obtain this is via *bagging* (which stands for *bootstrap aggregating*): several instances of the algorithm are run on random subsets of the training set, where the random subsets are selected with replacement. The method works great to reduce overfitting; an example is the Random Forest. \n",
    "\n",
    "### Boosting methods\n",
    "\n",
    "The estimators are run sequentially so that you have several weak learners combined, and this reduces the bias. Boosting works better than bagging on noisy data; an example is AdaBoost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO has to be massively improved, has to become a generic overview of ML and how to do it\n",
    "\n",
    "* regression/classification\n",
    "* clustering\n",
    "* feat eng\n",
    "* statistical vs. ML approaches\n",
    "* cost functions\n",
    "* overfitting/underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "\n",
    "### Regression\n",
    "\n",
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "> TODO to be improved/changed\n",
    "\n",
    "1. Define the problem and check if the data you have is good and informative enough\n",
    "2. Feature engineering\n",
    "3. Choose a set of algorithms\n",
    "4. Do cross-validation\n",
    "5. Examine the metrics\n",
    "6. Regularize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
